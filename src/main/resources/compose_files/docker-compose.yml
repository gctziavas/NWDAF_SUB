version: '3.8'
networks:
  monitor-net:
    driver: bridge
name: dockprom
services:
  db:
    container_name: pg_container
    image: postgres:alpine
    restart: always
    environment:
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
    ports:
      - "5432:5432"
    networks:
      - monitor-net
    volumes:
      - ../../../../../project-db-files/postgres-data:/var/lib/postgresql/data
      - ./schema.sql:/docker-entrypoint-initdb.d/schema.sql

  gadmin:
    container_name: pgadmin4_container
    image: dpage/pgadmin4
    user: root
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: "${POSTGRES_PASSWORD}"
    ports:
      - "5050:80"
    networks:
      - monitor-net
    volumes: 
      - ../../../../../project-db-files/pgadmin-data:/var/lib/pgadmin

  timescaledb:
    image: timescale/timescaledb:latest-pg12
    restart: always
    ports:
      - 5433:5433
    environment:
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
    networks:
      - monitor-net
    command: postgres -c port=5433
    volumes:
      - ../../../../../project-db-files/timescaledb-data:/var/lib/postgresql/data
      - ./timescaleSchema.sql:/docker-entrypoint-initdb.d/timescaleSchema.sql
  redis:
    container_name: redis
    image: redis/redis-stack:latest
    restart: always
    networks:
      - monitor-net
    ports:
      - "6379:6379"
      - "8001:8001"
    environment:
      - REDIS_PORT=6379
      - REDIS_DATABASES=16
  kafka-gen:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka-gen
    container_name: kafka-gen
    networks:
      - monitor-net
    volumes:
      - ./scripts/create_cluster_id.sh:/tmp/create_cluster_id.sh
      - ./clusterID:/tmp/clusterID
    command: "bash -c '/tmp/create_cluster_id.sh'"

  kafka1:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka1
    container_name: kafka1
    restart: always
    ports:
      - "39092:39092"
    networks:
      - monitor-net
    environment:
      KAFKA_LISTENERS: BROKER://kafka1:19092,EXTERNAL://kafka1:39092,CONTROLLER://kafka1:9093
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka1:19092,EXTERNAL://kafka1:39092
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:9093,2@kafka2:9093,3@kafka3:9093'
      KAFKA_METADATA_LOG_SEGMENT_MS: 15000
      KAFKA_METADATA_MAX_RETENTION_MS: 1200000
      KAFKA_METADATA_LOG_MAX_RECORD_BYTES_BETWEEN_SNAPSHOTS: 2800
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - kafka1-data:/var/lib/kafka/data
      - ./scripts/update_run.sh:/tmp/update_run.sh
      - ./clusterID:/tmp/clusterID
    command: "bash -c '/tmp/update_run.sh && /etc/confluent/docker/run'"

  kafka2:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka2
    container_name: kafka2
    ports:
      - "39093:39093"
    networks:
      - monitor-net
    environment:
      KAFKA_LISTENERS: BROKER://kafka2:19093,EXTERNAL://kafka2:39093,CONTROLLER://kafka2:9093
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka2:19093,EXTERNAL://kafka2:39093
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 2
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:9093,2@kafka2:9093,3@kafka3:9093'
      KAFKA_METADATA_LOG_SEGMENT_MS: 15000
      KAFKA_METADATA_MAX_RETENTION_MS: 1200000
      KAFKA_METADATA_LOG_MAX_RECORD_BYTES_BETWEEN_SNAPSHOTS: 2800
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - kafka2-data:/var/lib/kafka/data
      - ./scripts/update_run.sh:/tmp/update_run.sh
      - ./clusterID:/tmp/clusterID
    command: "bash -c '/tmp/update_run.sh && /etc/confluent/docker/run'"

  kafka3:
    image: confluentinc/cp-kafka:7.3.3
    hostname: kafka3
    container_name: kafka3
    ports:
      - "39094:39094"
    networks:
      - monitor-net
    environment:
      KAFKA_LISTENERS: BROKER://kafka3:19094,EXTERNAL://kafka3:39094,CONTROLLER://kafka3:9093
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka3:19094,EXTERNAL://kafka3:39094
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_PROCESS_ROLES: 'controller,broker'
      KAFKA_NODE_ID: 3
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:9093,2@kafka2:9093,3@kafka3:9093'
      KAFKA_METADATA_LOG_SEGMENT_MS: 15000
      KAFKA_METADATA_MAX_RETENTION_MS: 1200000
      KAFKA_METADATA_LOG_MAX_RECORD_BYTES_BETWEEN_SNAPSHOTS: 2800
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    volumes:
      - kafka3-data:/var/lib/kafka/data
      - ./scripts/update_run.sh:/tmp/update_run.sh
      - ./clusterID:/tmp/clusterID
    command: "bash -c '/tmp/update_run.sh && /etc/confluent/docker/run'"
  
  nwdafSubCollector:
    container_name: nwdafSubCollector
    image: thanlinardos/nwdaf_sub_collector:0.0.1-SNAPSHOT
    # restart: always
    ports:
      - "${collector_port}:${collector_port}"
      - "5006:5006"
    networks:
      - monitor-net
    environment:
      spring.kafka.bootstrap-servers: ${kafka1_host}:${kafka1_port}
      spring.kafka.consumer.group-id: events
      logging.level.org.apache.kafka: false
      nnwdaf-eventsubscription.prometheus_url: http://${prom_host}:${prom_port}/api/v1/query
      nnwdaf-eventsubscription.allow_dummy_data: true
  nwdafSub:
    container_name: nwdafSub
    image: thanlinardos/nwdaf_sub:0.0.2-SNAPSHOT
    restart: always
    tty: true
    ports:
      - "${server_port}:${server_port}"
      - "5005:5005"
    networks:
      - monitor-net
    links:
      - db
    environment:
      SPRING.PROFILES.ACTIVE: production
      nnwdaf-eventsubscription.openapi.dev_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.openapi.prod_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.client.dev_url: "https://${client_host}:${client_port}/client"
      nnwdaf-eventsubscription.client.prod_url: "https://${client_host}:${client_port}/client"
      nnwdaf-eventsubscription.init: false
      nnwdaf-eventsubscription.prometheus_url: http://${prom_host}:${prom_port}/api/v1/query
      nnwdaf-eventsubscription.containerNames: pg_container,pgadmin4_container,nwdafSub
      SPRING.DATASOURCE.NAME: eventsubscription
      SPRING.DATASOURCE.URL: jdbc:postgresql://db:5432/postgres?currentSchema=public 
      SPRING.DATASOURCE.USERNAME: "${POSTGRES_USER}"
      SPRING.DATASOURCE.PASSWORD: "${POSTGRES_PASSWORD}"
      SPRING.DATASOURCE.DRIVERCLASSNAME: org.postgresql.Driver
      EVENTNOTIFICATION.DATASOURCE.NAME: eventnotification
      EVENTNOTIFICATION.DATASOURCE.URL: jdbc:postgresql://db:5432/test?currentSchema=public 
      EVENTNOTIFICATION.DATASOURCE.USERNAME: "${POSTGRES_USER}"
      EVENTNOTIFICATION.DATASOURCE.PASSWORD: "${POSTGRES_PASSWORD}"
      EVENTNOTIFICATION.DATASOURCE.DRIVERCLASSNAME: org.postgresql.Driver
      EVENTMETRICS.DATASOURCE.NAME: eventmetrics
      EVENTMETRICS.DATASOURCE.URL: jdbc:postgresql://timescaledb:5433/metrics?currentSchema=public
      EVENTMETRICS.DATASOURCE.USERNAME: "${POSTGRES_USER}"
      EVENTMETRICS.DATASOURCE.PASSWORD: "${POSTGRES_PASSWORD}"
      EVENTMETRICS.DATASOURCE.DRIVERCLASSNAME: org.postgresql.Driver
      SERVER.PORT: "${server_port}"
      management.endpoint.health.show-details: always
      # logging.level.org.hibernate.SQL: DEBUG
      # logging.level.org.hibernate.type.descriptor.sql.BasicBinder: TRACE
      spring.kafka.bootstrap-servers: ${kafka1_host}:${kafka1_port}
      spring.kafka.consumer.group-id: events
      logging.level.org.apache.kafka: false
      spring.data.redis.host: redis
      spring.data.redis.port: 6379
  nwdafSubClient:
    container_name: nwdafSubClient
    image: thanlinardos/nwdaf_sub_client:0.0.2-SNAPSHOT
    restart: always
    tty: true
    ports:
      - "${client_port}:${client_port}"
      - "5007:5007"
    networks:
      - monitor-net
    environment:
      springdoc.enable-native-support: true
      springdoc.swagger-ui.path: /swagger-ui
      server.port: "${client_port}"
      nnwdaf-eventsubscription.openapi.dev_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.openapi.prod_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.client.dev_url: "https://${client_host}:${client_port}/client"
      nnwdaf-eventsubscription.client.prod_url: "https://${client_host}:${client_port}/client"
      nnwdaf-eventsubscription.init: false
      #spring configuration:
      spring.datasource.generate-unique-name: false
      spring.datasource.name: eventsubscription
      spring.profiles.active: production

      #endpoints:
      management.endpoint.health.show-details: always
  nwdafSubClient2:
    container_name: nwdafSubClient2
    image: thanlinardos/nwdaf_sub_client:0.0.2-SNAPSHOT
    restart: always
    tty: true
    ports:
      - "${client_port2}:${client_port2}"
      - "5008:5008"
    networks:
      - monitor-net
    environment:
      springdoc.enable-native-support: true
      springdoc.swagger-ui.path: /swagger-ui
      server.port: "${client_port2}"
      nnwdaf-eventsubscription.openapi.dev_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.openapi.prod_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.client.dev_url: "https://${client_host2}:${client_port2}/client"
      nnwdaf-eventsubscription.client.prod_url: "https://${client_host2}:${client_port2}/client"
      nnwdaf-eventsubscription.init: false
      #spring configuration:
      spring.datasource.generate-unique-name: false
      spring.datasource.name: eventsubscription
      spring.profiles.active: production

      #endpoints:
      management.endpoint.health.show-details: always
  nwdafSubClient3:
    container_name: nwdafSubClient3
    image: thanlinardos/nwdaf_sub_client:0.0.2-SNAPSHOT
    restart: always
    tty: true
    ports:
      - "${client_port3}:${client_port3}"
      - "5009:5009"
    networks:
      - monitor-net
    environment:
      springdoc.enable-native-support: true
      springdoc.swagger-ui.path: /swagger-ui
      server.port: "${client_port3}"
      nnwdaf-eventsubscription.openapi.dev_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.openapi.prod_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.client.dev_url: "https://${client_host3}:${client_port3}/client"
      nnwdaf-eventsubscription.client.prod_url: "https://${client_host3}:${client_port3}/client"
      nnwdaf-eventsubscription.init: false
      #spring configuration:
      spring.datasource.generate-unique-name: false
      spring.datasource.name: eventsubscription
      spring.profiles.active: production

      #endpoints:
      management.endpoint.health.show-details: always
  nwdafSubClient4:
    container_name: nwdafSubClient4
    image: thanlinardos/nwdaf_sub_client:0.0.2-SNAPSHOT
    restart: always
    tty: true
    ports:
      - "${client_port4}:${client_port4}"
      - "5010:5010"
    networks:
      - monitor-net
    environment:
      springdoc.enable-native-support: true
      springdoc.swagger-ui.path: /swagger-ui
      server.port: "${client_port4}"
      nnwdaf-eventsubscription.openapi.dev_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.openapi.prod_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.client.dev_url: "https://${client_host4}:${client_port4}/client"
      nnwdaf-eventsubscription.client.prod_url: "https://${client_host4}:${client_port4}/client"
      nnwdaf-eventsubscription.init: false
      #spring configuration:
      spring.datasource.generate-unique-name: false
      spring.datasource.name: eventsubscription
      spring.profiles.active: production

      #endpoints:
      management.endpoint.health.show-details: always
  nwdafSubClient5:
    container_name: nwdafSubClient5
    image: thanlinardos/nwdaf_sub_client:0.0.2-SNAPSHOT
    restart: always
    tty: true
    ports:
      - "${client_port5}:${client_port5}"
      - "5011:5011"
    networks:
      - monitor-net
    environment:
      springdoc.enable-native-support: true
      springdoc.swagger-ui.path: /swagger-ui
      server.port: "${client_port5}"
      nnwdaf-eventsubscription.openapi.dev_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.openapi.prod_url: "https://${server_host}:${server_port}"
      nnwdaf-eventsubscription.client.dev_url: "https://${client_host5}:${client_port5}/client"
      nnwdaf-eventsubscription.client.prod_url: "https://${client_host5}:${client_port5}/client"
      nnwdaf-eventsubscription.init: false
      #spring configuration:
      spring.datasource.generate-unique-name: false
      spring.datasource.name: eventsubscription
      spring.profiles.active: production

      #endpoints:
      management.endpoint.health.show-details: always
volumes:
  kafka1-data:
  kafka2-data:
  kafka3-data:  
# https://github.com/katyagorshkova/kafka-kraft
      
